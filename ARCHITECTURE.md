# ğŸ—ï¸ Buffett's Brain - System Architecture & Technical Documentation

## Overview

This document provides a comprehensive technical view of Buffett's Brain, from initial setup through query processing with intelligent routing and response generation.

---

## ğŸ¯ High-Level Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          BUFFETT'S BRAIN V1.0                           â”‚
â”‚                    Hybrid RAG with Intelligent Routing                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                                   â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Knowledge Base â”‚              â”‚   Real-Time Data   â”‚
            â”‚  (RAG Pipeline) â”‚              â”‚  (Web Search API)  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚                                   â”‚
                    â”‚        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â–º  LLM Router  â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚ (Llama 3.1)  â”‚
                             â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                    â”‚
                             â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                             â”‚   Response   â”‚
                             â”‚  Synthesis   â”‚
                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š Complete System Flowchart
```
                              [USER STARTS HERE]
                                      â”‚
                                      â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                    PHASE 1: SETUP & INSTALLATION                    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                                   â”‚
                    â–¼                                   â–¼
            [Install Python 3.11+]              [Clone Repository]
            [Create venv]                       [Install dependencies]
                    â”‚                                   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â–¼
                            [Create .env file]
                    [Add GROQ_API_KEY & TAVILY_API_KEY]
                                      â”‚
                                      â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                 PHASE 2: KNOWLEDGE BASE CREATION                    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   download_data.py      â”‚
                        â”‚   [Fetch Documents]     â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚                         â”‚                         â”‚
            â–¼                         â–¼                         â–¼
    [Berkshire Letters]      [Poor Charlie's]         [Munger Speeches]
    [1977-2024 PDFs]         [Almanack PDF]           [Transcripts]
    [~1,900 pages]           [~150 pages]             [~54 pages]
            â”‚                         â”‚                         â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                         [2,104 total pages stored]
                                      â”‚
                                      â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚ process_documents.py    â”‚
                        â”‚ [Process & Embed]       â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â–¼                         â–¼                         â–¼
    [Load PDFs]              [Split into chunks]      [Generate embeddings]
    [PyPDFDirectoryLoader]   [1000 chars, 200         [HuggingFace]
                              overlap]                [all-MiniLM-L6-v2]
    [2,104 pages]            [7,921 chunks]           [384 dimensions]
            â”‚                         â”‚                         â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â–¼
                        [Store in ChromaDB Vector DB]
                        [knowledge_base/vector_db/]
                        [Persisted locally - no API calls]
                                      â”‚
                                      â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                   PHASE 3: USER INTERACTION                         â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                                   â”‚
                    â–¼                                   â–¼
            [streamlit run app3.py]         [streamlit run app2.py]
            (V1.0 - LLM Routing)            (V0.7 - Keyword Routing)
                    â”‚                                   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â–¼
                            [User Enters Query]
                                      â”‚
                                      â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚              PHASE 4: INTELLIGENT QUERY ROUTING (V1.0)              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚  Time-Sensitive Check   â”‚
                        â”‚  (yesterday, today,     â”‚
                        â”‚   current, price, etc.) â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚                           â”‚
                    YES â”‚                           â”‚ NO
                        â–¼                           â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  WEB SEARCH PATH  â”‚       â”‚   RAG PATH        â”‚
            â”‚  (Skip RAG)       â”‚       â”‚   (Check KB First)â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚                           â”‚
                      â”‚                           â–¼
                      â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚               â”‚ 1. Retrieve from RAG  â”‚
                      â”‚               â”‚    (k=4 chunks)       â”‚
                      â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚                           â”‚
                      â”‚                           â–¼
                      â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚               â”‚ 2. LLM Evaluator      â”‚
                      â”‚               â”‚    Score 1-10         â”‚
                      â”‚               â”‚    (Llama 3.1 8B)     â”‚
                      â”‚               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚                           â”‚
                      â”‚               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚               â”‚                       â”‚
                      â”‚           Score â‰¥5?              Score <5?
                      â”‚               â”‚                       â”‚
                      â”‚               â–¼                       â–¼
                      â”‚       [USE RAG CONTEXT]      [TRIGGER SEARCH]
                      â”‚               â”‚                       â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                    PHASE 5: INFORMATION RETRIEVAL                   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚                           â”‚
                        â–¼                           â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   RAG RETRIEVAL   â”‚       â”‚   WEB SEARCH      â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚                           â”‚
                        â–¼                           â–¼
            [Embed query with]          [Tavily Advanced Search]
            [HuggingFace model]         [max_results=3]
                        â”‚                           â”‚
                        â–¼                           â–¼
            [Search ChromaDB]           [Return search snippets]
            [Semantic similarity]       [with URLs]
                        â”‚                           â”‚
                        â–¼                           â–¼
            [Top 4 chunks from]         [Format results with]
            [Buffett/Munger docs]       [source attribution]
                        â”‚                           â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
                            [Combine Retrieved Context]
                                      â”‚
                                      â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                   PHASE 6: RESPONSE GENERATION                      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   Format Prompt         â”‚
                        â”‚   â€¢ System instruction  â”‚
                        â”‚   â€¢ Retrieved context   â”‚
                        â”‚   â€¢ User question       â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚   Groq API              â”‚
                        â”‚   Llama 3.1 8B Instant  â”‚
                        â”‚   (temperature=0.0)     â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
                        [Generate Response]
                        [Grounded in sources]
                        [~200ms latency]
                                      â”‚
                                      â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                   PHASE 7: RESPONSE DELIVERY                        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
                        [Display in Streamlit]
                        [Scrolling chat interface]
                        [With source attribution]
                                      â”‚
                                      â–¼
                        [User Can Ask Follow-up]
                                      â”‚
                                      â–¼
                        [Loop back to Query Input]
```

---

## ğŸ”‘ Key Architectural Decisions

### Decision 1: Groq over OpenAI/Anthropic

**Rationale:**
- âš¡ 10-100x faster inference (~200ms vs 2-5s)
- ğŸ’° Cost-effective free tier
- ğŸ”§ No dependency conflicts
- ğŸ“ˆ Sufficient quality for domain tasks

**Tradeoff:** Slightly less capable than GPT-4, but speed makes up for it in user experience.

### Decision 2: HuggingFace Embeddings over OpenAI

**Rationale:**
- ğŸ†“ Completely free (no API costs)
- ğŸ  Runs locally (no network latency)
- ğŸš« No quota limits
- âœ… Excellent quality (384-dim all-MiniLM-L6-v2)

**Tradeoff:** Initial model download (~90MB), but cached after first run.

### Decision 3: Hybrid Routing (Time-Sensitive + LLM Evaluation)

**Rationale:**
- ğŸ¯ Keywords catch obvious time-sensitive queries (yesterday, today, price)
- ğŸ§  LLM evaluation handles nuanced cases
- ğŸ›¡ï¸ Fallback strategy prevents false negatives

**Tradeoff:** Adds ~200ms per query for evaluation, but worth it for accuracy.

### Decision 4: Tavily over Google Search API

**Rationale:**
- ğŸ¤– Built specifically for LLM applications
- ğŸ“Š Returns structured, clean snippets
- ğŸ’µ More generous free tier
- ğŸ“ Better result quality for text-based queries

**Tradeoff:** Doesn't extract structured data (stock prices) - acknowledged limitation.

---

## ğŸ”¬ RAG Pipeline: Technical Deep Dive

### Component Specifications

| Component | Technology | Configuration | Purpose |
|-----------|-----------|---------------|---------|
| **Embeddings** | HuggingFace all-MiniLM-L6-v2 | 384 dimensions | Convert text to semantic vectors |
| **Vector DB** | ChromaDB | Persistent storage | Fast similarity search |
| **Retriever** | LangChain | k=4 chunks | Fetch most relevant context |
| **LLM (Main)** | Groq Llama 3.1 8B | temp=0.0, max_tokens=2048 | Generate final responses |
| **LLM (Evaluator)** | Groq Llama 3.1 8B | temp=0.0, max_tokens=100 | Score RAG relevance |
| **Search** | Tavily Advanced | max_results=3 | Real-time web data |

### Document Processing Pipeline
```python
# Step 1: Load Documents
PyPDFDirectoryLoader("knowledge_base/docs/")
    â†’ 2,104 pages loaded

# Step 2: Chunk Documents
RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200,
    length_function=len
)
    â†’ 7,921 chunks created

# Step 3: Generate Embeddings
HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-MiniLM-L6-v2"
)
    â†’ 7,921 Ã— 384-dimensional vectors

# Step 4: Store in Vector DB
Chroma.from_documents(
    chunks,
    embedding_function,
    persist_directory="knowledge_base/vector_db"
)
    â†’ Indexed and persisted locally
```

### Query Processing Pipeline (V1.0)
```python
# Stage 1: Time-Sensitive Detection
time_keywords = ['yesterday', 'today', 'current', 'price', ...]
is_time_sensitive = any(keyword in query.lower() for keyword in time_keywords)

if is_time_sensitive:
    # Skip RAG, go straight to search
    use_search = True
else:
    # Stage 2: RAG Retrieval
    rag_docs = retriever.invoke(query)  # k=4 chunks
    rag_context = combine(rag_docs)
    
    # Stage 3: LLM Evaluation
    relevance_score = evaluate_rag_relevance(query, rag_context, llm)
    # Returns 1-10 score
    
    # Stage 4: Routing Decision
    if relevance_score >= 5:
        use_rag = True
    else:
        use_search = True  # Fallback

# Stage 5: Execute Search (if needed)
if use_search:
    search_results = tavily_search.invoke(query)
    context = format(search_results)

# Stage 6: Generate Response
prompt = format_prompt(context, query)
response = groq_llm.invoke(prompt)
```

---

## ğŸ¨ Version Comparison

### V0.7 (app2.py) - Keyword-Based Routing
```python
search_keywords = ['current', 'today', 'price', ...]
rag_keywords = ['buffett', 'munger', 'philosophy', ...]

if any(keyword in query for keyword in search_keywords):
    use_search = True
elif any(keyword in query for keyword in rag_keywords):
    use_rag = True
else:
    use_rag = True  # Default
```

**Pros:** Simple, fast, predictable  
**Cons:** Brittle, misses nuanced queries, hard to maintain

### V1.0 (app3.py) - LLM-Based Routing
```python
# Explicit time-sensitive detection
if is_time_sensitive(query):
    use_search = True
else:
    # LLM evaluates if RAG can answer
    score = llm_evaluate(query, rag_context)  # 1-10
    
    if score >= 5:
        use_rag = True
    else:
        use_search = True
```

**Pros:** Intelligent, handles nuance, adapts to query intent  
**Cons:** Adds ~200ms latency, requires extra LLM call

---

## ğŸ“ˆ Performance Characteristics

| Metric | Value | Notes |
|--------|-------|-------|
| **Total Documents** | 2,104 pages | Buffett/Munger corpus |
| **Total Chunks** | 7,921 | After text splitting |
| **Chunk Size** | 1,000 chars | With 200-char overlap |
| **Embedding Dimension** | 384 | all-MiniLM-L6-v2 |
| **Retrieval Count** | k=4 | Top chunks per query |
| **LLM Latency** | ~200ms | Groq Llama 3.1 8B |
| **Total Query Time** | 0.5-1.5s | Including retrieval + generation |
| **Evaluation Overhead** | ~200ms | LLM relevance scoring |
| **Search Latency** | ~500ms | Tavily API call |

---

## ğŸ›¡ï¸ Security & Best Practices

### API Key Management
- âœ… Stored in `.env` file (never committed)
- âœ… `.gitignore` prevents accidental exposure
- âœ… `.env.example` provided as template
- âš ï¸ Users must obtain their own keys

### Data Privacy
- âœ… Vector DB stored locally
- âœ… No document data sent to third parties
- âœ… Only queries sent to LLM APIs
- âœ… HuggingFace embeddings run locally

### Code Quality
- âœ… Comprehensive test suite (pytest)
- âœ… Type hints where appropriate
- âœ… Docstrings for all functions
- âœ… Error handling with graceful fallbacks

---

## ğŸ”„ Data Flow Summary

### RAG Query Flow
```
User Query
    â†“
Embed with HuggingFace (local)
    â†“
Search ChromaDB (similarity)
    â†“
Retrieve Top 4 Chunks
    â†“
LLM Evaluates Relevance (1-10)
    â†“
If score â‰¥5: Use RAG context
If score <5: Trigger web search
    â†“
Format Prompt with Context
    â†“
Groq Llama 3.1 8B Generation
    â†“
Display Response to User
```

### Time-Sensitive Query Flow
```
User Query (contains: yesterday, today, price, etc.)
    â†“
Detect Time-Sensitive Keywords
    â†“
Skip RAG Evaluation
    â†“
Tavily Web Search (max_results=3)
    â†“
Format Search Results
    â†“
Groq Llama 3.1 8B Generation
    â†“
Display Response to User
```

---

## ğŸ“ File Structure
```
buffetts_brain/
â”œâ”€â”€ .env                                # API keys (gitignored)
â”œâ”€â”€ .env.example                        # Template for users
â”œâ”€â”€ .gitignore                          # Git exclusions
â”œâ”€â”€ LICENSE                             # MIT License
â”œâ”€â”€ README.md                           # Main documentation
â”œâ”€â”€ ARCHITECTURE.md                     # This file
â”œâ”€â”€ CONTRIBUTING.md                     # Contribution guidelines
â”œâ”€â”€ CHANGELOG.md                        # Version history
â”œâ”€â”€ requirements.txt                    # Python dependencies
â”œâ”€â”€ download_data.py                    # Document fetcher
â”œâ”€â”€ process_documents.py                # Document processor (HuggingFace embeddings)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app2.py                         # V0.7 (keyword-based routing)
â”‚   â””â”€â”€ app3.py                         # V1.0 (LLM-based routing) â­
â”œâ”€â”€ tests/                              # Test suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py                     # Pytest fixtures
â”‚   â”œâ”€â”€ test_rag_pipeline.py            # RAG tests
â”‚   â”œâ”€â”€ test_query_routing.py          # Routing logic tests
â”‚   â”œâ”€â”€ test_embeddings.py              # Embedding tests
â”‚   â”œâ”€â”€ test_integration.py             # End-to-end tests
â”‚   â”œâ”€â”€ requirements-test.txt           # Test dependencies
â”‚   â””â”€â”€ README.md                       # Test documentation
â””â”€â”€ knowledge_base/
    â”œâ”€â”€ docs/                           # Source documents
    â”‚   â”œâ”€â”€ Berkshire_Letters/          # 1977-2024 annual letters
    â”‚   â”œâ”€â”€ Munger_Transcripts/         # Speeches & transcripts
    â”‚   â””â”€â”€ Poor_Charlies_Almanack.pdf  # Full book
    â””â”€â”€ vector_db/                      # ChromaDB storage (gitignored)
```

---

## ğŸš€ Deployment Considerations

### Local Development
- âœ… Works out of the box with free tier APIs
- âœ… Vector DB stored locally (no cloud required)
- âœ… HuggingFace models cached locally

### Production Deployment (Future V2.0)
**Recommended Stack:**
- **Backend**: FastAPI for API endpoints
- **Vector DB**: Keep Chroma or migrate to Pinecone for scale
- **LLM**: Groq or self-hosted Llama
- **Search**: Dedicated financial APIs (Alpha Vantage, Polygon.io)
- **Hosting**: AWS/GCP with Docker containers
- **Monitoring**: LangSmith for tracing

---

## ğŸ› Known Limitations & Workarounds

### Limitation 1: Web Search Snippets
**Issue**: Tavily returns references to data sources, not raw numerical data  
**Workaround**: Acknowledge limitation in response, provide URLs  
**V2 Solution**: Integrate Alpha Vantage or Polygon.io for structured financial data

### Limitation 2: LLM Context Ignoring
**Issue**: LLM occasionally gives generic advice despite provided context  
**Workaround**: Very explicit prompting ("USE THE DATA PROVIDED")  
**V2 Solution**: Fine-tune model on financial Q&A pairs

### Limitation 3: Relevance Evaluation Strictness
**Issue**: Early versions scored too generously (historical info for current queries)  
**Workaround**: Explicit time-sensitive keyword detection + strict evaluation criteria  
**V2 Solution**: Train a specialized classifier for "can RAG answer this?"

### Limitation 4: Knowledge Base Freshness
**Issue**: RAG only knows documents up to processing date  
**Workaround**: Re-run `process_documents.py` periodically  
**V2 Solution**: Automated document fetching + incremental indexing

---

## ğŸ”® Future Architecture (V2.0 Roadmap)

### Multi-Agent System
```
                    [User Query]
                         â”‚
                         â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚    Router Agent        â”‚
            â”‚  (Classify query type) â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                â”‚                â”‚
        â–¼                â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RAG Agent   â”‚  â”‚ Search Agent â”‚  â”‚Financial Agentâ”‚
â”‚ (Historical) â”‚  â”‚ (Current)    â”‚  â”‚ (Numerical)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                â”‚                â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Synthesizer Agent     â”‚
            â”‚  (Combine & Format)    â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Fine-Tuning Strategy

1. **Collect Training Data**: Log queries + preferred responses
2. **Create Q&A Pairs**: Format as instruction-tuning dataset
3. **Fine-Tune Llama 3.1 8B**: On financial domain + Buffett style
4. **A/B Test**: Compare base model vs fine-tuned
5. **Iterate**: Continuous improvement loop

### Financial API Integration
```python
# V2 Example
if query_about_stock_price(query):
    # Use Alpha Vantage instead of web search
    price_data = alpha_vantage.get_quote(ticker)
    context = format_price_data(price_data)
else:
    # Use RAG as before
    context = rag_retrieval(query)
```

---

## ğŸ“ Learning Resources

### Understanding This Architecture

- **RAG Basics**: [LangChain RAG Tutorial](https://python.langchain.com/docs/use_cases/question_answering/)
- **Vector Databases**: [ChromaDB Documentation](https://docs.trychroma.com/)
- **Embeddings**: [Sentence Transformers Guide](https://www.sbert.net/)
- **Groq API**: [Groq Documentation](https://console.groq.com/docs)

---

## ğŸ“ Questions About Architecture?

For questions about architectural decisions, tradeoffs, or implementation details:
- See [README.md](README.md) for high-level overview
- See [CONTRIBUTING.md](CONTRIBUTING.md) for development guidelines
- Open an issue on GitHub for specific technical questions

---

**Built with â¤ï¸ and rigorous engineering by Cristian Perera**

*"The best investment you can make is in yourself." - Warren Buffett*